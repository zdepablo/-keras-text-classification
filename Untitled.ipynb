{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GRID K520 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 7s - loss: 1.0776 - acc: 0.6237     \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.7521 - acc: 0.7440     \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.6354 - acc: 0.7869     \n",
      "19840/20000 [============================>.] - ETA: 0sEpoch 1/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.9209 - acc: 0.6854     \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.5617 - acc: 0.8200     \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.4681 - acc: 0.8525     \n",
      "20000/20000 [==============================] - 1s     \n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.9940 - acc: 0.6625     \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.6456 - acc: 0.7874     \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.5304 - acc: 0.8286     \n",
      "19968/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.8952 - acc: 0.6951     \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.5765 - acc: 0.8094     \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.4665 - acc: 0.8491     \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3935 - acc: 0.8729     \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3618 - acc: 0.8820     \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3372 - acc: 0.8930     \n",
      "19904/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.9280 - acc: 0.6921     \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.6085 - acc: 0.8048     \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.5135 - acc: 0.8367     \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.4325 - acc: 0.8620     \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3877 - acc: 0.8770     \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3586 - acc: 0.8866     \n",
      "19968/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.8138 - acc: 0.7266     \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.4927 - acc: 0.8399     \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.4228 - acc: 0.8669     \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3830 - acc: 0.8805     \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3532 - acc: 0.8907     \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3355 - acc: 0.8945     \n",
      "19936/20000 [============================>.] - ETA: 0sEpoch 1/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.6596 - acc: 0.7908     \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.3692 - acc: 0.8881     \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.2953 - acc: 0.9107     \n",
      "19872/20000 [============================>.] - ETA: 0sEpoch 1/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.6465 - acc: 0.7952     \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.3788 - acc: 0.8853     \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.3111 - acc: 0.9089     \n",
      "19872/20000 [============================>.] - ETA: 0sEpoch 1/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.6586 - acc: 0.7858     \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.3675 - acc: 0.8879     \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.2899 - acc: 0.9111     \n",
      "19968/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.6325 - acc: 0.7968     \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3468 - acc: 0.8953     \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2730 - acc: 0.9184     \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2436 - acc: 0.9258     \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2199 - acc: 0.9352     \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2029 - acc: 0.9401     \n",
      "19904/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.5953 - acc: 0.8116     \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3286 - acc: 0.9015     \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2771 - acc: 0.9175     \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2388 - acc: 0.9292     \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2105 - acc: 0.9390     \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.1954 - acc: 0.9426     \n",
      "19872/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.6209 - acc: 0.8029     \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3468 - acc: 0.8959     \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2880 - acc: 0.9151     \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2475 - acc: 0.9268     \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2185 - acc: 0.9367     \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.1995 - acc: 0.9421     \n",
      "20000/20000 [==============================] - 1s     \n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.7585 - acc: 0.7524     \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.4413 - acc: 0.8617     \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.3772 - acc: 0.8824     \n",
      "19936/20000 [============================>.] - ETA: 0sEpoch 1/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.7044 - acc: 0.7698     \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.3980 - acc: 0.8754     \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.3449 - acc: 0.8919     \n",
      "20000/20000 [==============================] - 1s     \n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.9120 - acc: 0.6914     \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.5371 - acc: 0.8263     \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.4312 - acc: 0.8613     \n",
      "19968/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.7747 - acc: 0.7430     \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.4437 - acc: 0.8611     \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3731 - acc: 0.8820     \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3337 - acc: 0.8947     \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3022 - acc: 0.9053     \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2804 - acc: 0.9118     \n",
      "19936/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.8560 - acc: 0.7117     \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.4869 - acc: 0.8478     \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.4066 - acc: 0.8734     \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3595 - acc: 0.8862     \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3231 - acc: 0.9009     \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2996 - acc: 0.9091     \n",
      "20000/20000 [==============================] - 1s     \n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.8505 - acc: 0.7147     \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.4751 - acc: 0.8480     \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3915 - acc: 0.8793     \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3469 - acc: 0.8900     \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3205 - acc: 0.8994     \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2909 - acc: 0.9097     \n",
      "19840/20000 [============================>.] - ETA: 0sEpoch 1/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.5230 - acc: 0.8347     \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.2655 - acc: 0.9218     \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.2166 - acc: 0.9361     \n",
      "19904/20000 [============================>.] - ETA: 0sEpoch 1/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.5970 - acc: 0.8107     \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.3135 - acc: 0.9085     \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.2499 - acc: 0.9271     \n",
      "19968/20000 [============================>.] - ETA: 0sEpoch 1/3\n",
      "40000/40000 [==============================] - 8s - loss: 0.6224 - acc: 0.8041     \n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.2960 - acc: 0.9136     \n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 7s - loss: 0.2304 - acc: 0.9320     \n",
      "19968/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.5512 - acc: 0.8256     \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2584 - acc: 0.9217     \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2090 - acc: 0.9390     \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.1813 - acc: 0.9483     \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.1632 - acc: 0.9516     \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.1499 - acc: 0.9558     \n",
      "20000/20000 [==============================] - 1s     \n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.5956 - acc: 0.8135     \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.3026 - acc: 0.9115     \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2335 - acc: 0.9323     \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2048 - acc: 0.9407     \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.1827 - acc: 0.9462     \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.1694 - acc: 0.9498     \n",
      "19936/20000 [============================>.] - ETA: 0sEpoch 1/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.5755 - acc: 0.8178     \n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2782 - acc: 0.9166     \n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.2307 - acc: 0.9325     \n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.1997 - acc: 0.9423     \n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.1770 - acc: 0.9488     \n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 7s - loss: 0.1644 - acc: 0.9533     \n",
      "20000/20000 [==============================] - 1s     \n",
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 12s - loss: 0.5109 - acc: 0.8420    \n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 11s - loss: 0.2502 - acc: 0.9265    \n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 11s - loss: 0.1997 - acc: 0.9429    \n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 11s - loss: 0.1722 - acc: 0.9507    \n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 11s - loss: 0.1548 - acc: 0.9553    \n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 11s - loss: 0.1414 - acc: 0.9596    \n",
      "The parameters of the best model are: \n",
      "{'dense_layer_sizes': [64, 64], 'nb_conv': 3, 'nb_pool': 2, 'nb_epoch': 6, 'nb_filters': 8}\n",
      " 9984/10000 [============================>.] - ETA: 0sloss :  0.0584021114599\n",
      "acc :  0.9828\n"
     ]
    }
   ],
   "source": [
    "'''Example of how to use sklearn wrapper\n",
    "\n",
    "Builds simple CNN models on MNIST and uses sklearn's GridSearchCV to find best model\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# load training data and do basic data normalization\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "def make_model(dense_layer_sizes, nb_filters, nb_conv, nb_pool):\n",
    "    '''Creates model comprised of 2 convolutional layers followed by dense layers\n",
    "\n",
    "    dense_layer_sizes: List of layer sizes. This list has one number for each layer\n",
    "    nb_filters: Number of convolutional filters in each convolutional layer\n",
    "    nb_conv: Convolutional kernel size\n",
    "    nb_pool: Size of pooling area for max pooling\n",
    "    '''\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                            border_mode='valid',\n",
    "                            input_shape=(1, img_rows, img_cols)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    for layer_size in dense_layer_sizes:\n",
    "        model.add(Dense(layer_size))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "dense_size_candidates = [[32], [64], [32, 32], [64, 64]]\n",
    "my_classifier = KerasClassifier(make_model, batch_size=32)\n",
    "validator = GridSearchCV(my_classifier,\n",
    "                         param_grid={'dense_layer_sizes': dense_size_candidates,\n",
    "                                     # nb_epoch is avail for tuning even when not\n",
    "                                     # an argument to model building function\n",
    "                                     'nb_epoch': [3, 6],\n",
    "                                     'nb_filters': [8],\n",
    "                                     'nb_conv': [3],\n",
    "                                     'nb_pool': [2]},\n",
    "                         scoring='log_loss',\n",
    "                         n_jobs=1)\n",
    "validator.fit(X_train, y_train)\n",
    "\n",
    "print('The parameters of the best model are: ')\n",
    "print(validator.best_params_)\n",
    "\n",
    "# validator.best_estimator_ returns sklearn-wrapped version of best model.\n",
    "# validator.best_estimator_.model returns the (unwrapped) keras model\n",
    "best_model = validator.best_estimator_.model\n",
    "metric_names = best_model.metrics_names\n",
    "metric_values = best_model.evaluate(X_test, y_test)\n",
    "for metric, value in zip(metric_names, metric_values):\n",
    "    print(metric, ': ', value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7fac8d5d9350>,\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'dense_layer_sizes': [[32], [64], [32, 32], [64, 64]], 'nb_epoch': [3, 6], 'nb_pool': [2], 'nb_conv': [3], 'nb_filters': [8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='log_loss', verbose=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dense_layer_sizes': [64, 64],\n",
       " 'nb_conv': 3,\n",
       " 'nb_epoch': 6,\n",
       " 'nb_filters': 8,\n",
       " 'nb_pool': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x7fac52b4e390>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
